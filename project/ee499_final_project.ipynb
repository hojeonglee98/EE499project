{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE499 Final Project\n",
    "# Premier League Predictor\n",
    "Hojeong Lee and Nate Chism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from autograd import grad \n",
    "from autograd import hessian\n",
    "import math\n",
    "import copy\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "readDataPath = './readData/'\n",
    "sys.path.append('./')\n",
    "\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4070, 114)\n",
      "[[0 'https://www.premierleague.com/match/7186' '10/11' ... 0.78 -4.0 55.6]\n",
      " [1 'https://www.premierleague.com/match/7404' '10/11' ... 0.32 17.0 60.2]\n",
      " [2 'https://www.premierleague.com/match/7255' '10/11' ... 0.38 9.0 66.7]\n",
      " ...\n",
      " [4067 'https://www.premierleague.com/match/59178' '20/21' ... 0.69 4.0\n",
      "  64.1]\n",
      " [4068 'https://www.premierleague.com/match/59182' '20/21' ... 0.42 6.0\n",
      "  54.2]\n",
      " [4069 'https://www.premierleague.com/match/59052' '20/21' ... 0.87 5.0\n",
      "  71.1]]\n"
     ]
    }
   ],
   "source": [
    "season_data = pd.read_csv('./readData/df_full_premierleague.csv')\n",
    "season_csv_to_array = np.array(season_data)\n",
    "# print(range(0, len(house_csv_to_array) -1))\n",
    "print(season_csv_to_array.shape)\n",
    "print(season_csv_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "# 2, 4, 5, 6, 8 - 31, 38 - 49, 56  \n",
    "print(season_csv_to_array[5][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4070\n",
      "114\n",
      "[678.  -1.   0.]\n"
     ]
    }
   ],
   "source": [
    "i, j = season_csv_to_array.shape\n",
    "print(i)\n",
    "print(j)\n",
    "match_target_scores = np.zeros((i,3))\n",
    "# match_teams = np.array((i, 3))\n",
    "for it_1 in range(0, i):\n",
    "    # store game unique id\n",
    "    match_target_scores[it_1][0] = season_csv_to_array[it_1][0]\n",
    "    #store game unique id, home team, away team\n",
    "    # match_teams[it_1][0] = season_csv_to_array[it_1][0]\n",
    "    # match_teams[it_1][1] = season_csv_to_array[it_1][4]\n",
    "    # match_teams[it_1][2] = season_csv_to_array[it_1][5]\n",
    "    if season_csv_to_array[it_1][34] > 0:\n",
    "        match_target_scores[it_1][1] = 1\n",
    "    elif season_csv_to_array[it_1][34] < 0:\n",
    "        match_target_scores[it_1][1] = -1\n",
    "    else:\n",
    "        match_target_scores[it_1][1] = 0\n",
    "\n",
    "print(match_target_scores[678])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.   10.   15.    5.    9.    4.  609.   65.6   0.   19.    4.   23.\n",
      " 820.    2.   32.    3.    7.    0.  313.   34.4   0.    9.    4.   21.\n",
      " 527.    2.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0. ]\n"
     ]
    }
   ],
   "source": [
    "season_data_cleaned = np.zeros((i, 102))\n",
    "\n",
    "# print(season_csv_to_array[5])\n",
    "season_csv_to_array[pd.isnull(season_csv_to_array)] = 0\n",
    "# print(season_csv_to_array[5])\n",
    "# 2, 4, 5, 6, 8 - 31, 38 - 49, 56  \n",
    "for it in range(0, i):\n",
    "    ct = 0\n",
    "    for it2 in range(0, j):\n",
    "        \n",
    "        # if(np.isnan(season_csv_to_array[it][it2])):\n",
    "        #     print(season_csv_to_array[it][it2])\n",
    "\n",
    "        if it2 not in [1, 2, 3, 4, 5, 6, 7, 32, 33, 34, 35, 36, 37]:\n",
    "            season_data_cleaned[it][ct] = season_csv_to_array[it][it2]\n",
    "            # print(ct)\n",
    "            ct = ct + 1\n",
    "\n",
    "        elif it2 == 2:\n",
    "            season_number = (int)(season_csv_to_array[it][it2][0] + season_csv_to_array[it][it2][1])\n",
    "            season_data_cleaned[it][ct] = season_number\n",
    "            ct = ct + 1\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "# print(season_data_cleaned)\n",
    "print(season_data_cleaned[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:  4069  ct:  102  it2:  113\n"
     ]
    }
   ],
   "source": [
    "print(\"it: \", it, \" ct: \", ct, \" it2: \", it2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n"
     ]
    }
   ],
   "source": [
    "print(season_data_cleaned[4000][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_data_cleaned[123][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_10to18 = np.zeros((3419, 102))\n",
    "season_19 = np.zeros((380, 102))\n",
    "season_20 = np.zeros((271, 102))\n",
    "\n",
    "Y_train = np.zeros((3419,))\n",
    "Y_test1 = np.zeros((380,))\n",
    "Y_test2 = np.zeros((271,))\n",
    "\n",
    "ct1 = 0\n",
    "ct2 = 0\n",
    "ct3 = 0\n",
    "for it in range(0, i):\n",
    "    target_index = season_data_cleaned[it][0]\n",
    "    if season_data_cleaned[it][1] < 19:\n",
    "        seasons_10to18[ct1] = season_data_cleaned[it]\n",
    "        Y_train[ct1] = match_target_scores[it][1]\n",
    "        ct1 = ct1 + 1\n",
    "    elif season_data_cleaned[it][1] == 19:\n",
    "        season_19[ct2] = season_data_cleaned[it]\n",
    "        Y_test1[ct2] = match_target_scores[it][1]\n",
    "        ct2 = ct2 + 1\n",
    "        # print(it)\n",
    "    elif season_data_cleaned[it][1] == 20:\n",
    "        season_20[ct3] = season_data_cleaned[it]\n",
    "        Y_test2[ct3] = match_target_scores[it][1]\n",
    "        ct3 = ct3 + 1\n",
    "        # print(it)\n",
    "    else:\n",
    "        print('THIS SHOULD NEVER HAPPEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3419, 102)\n",
      "(380, 102)\n",
      "(271, 102)\n"
     ]
    }
   ],
   "source": [
    "print(seasons_10to18.shape)\n",
    "print(season_19.shape)\n",
    "print(season_20.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = seasons_10to18\n",
    "X_test1 = season_19\n",
    "X_test2 = season_20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPerceptron does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#model 1: Perceptron\u001b[39;00m\n\u001b[1;32m      3\u001b[0m perc_clf \u001b[39m=\u001b[39m Perceptron(tol\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m13\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m perc_clf\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[1;32m      5\u001b[0m Perceptron()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee499_ML/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:890\u001b[0m, in \u001b[0;36mBaseSGDClassifier.fit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, coef_init\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, intercept_init\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    863\u001b[0m     \u001b[39m\"\"\"Fit linear model with Stochastic Gradient Descent.\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \n\u001b[1;32m    865\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[39m        Returns an instance of self.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 890\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    891\u001b[0m         X,\n\u001b[1;32m    892\u001b[0m         y,\n\u001b[1;32m    893\u001b[0m         alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha,\n\u001b[1;32m    894\u001b[0m         C\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m    895\u001b[0m         loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss,\n\u001b[1;32m    896\u001b[0m         learning_rate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[1;32m    897\u001b[0m         coef_init\u001b[39m=\u001b[39;49mcoef_init,\n\u001b[1;32m    898\u001b[0m         intercept_init\u001b[39m=\u001b[39;49mintercept_init,\n\u001b[1;32m    899\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    900\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee499_ML/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:686\u001b[0m, in \u001b[0;36mBaseSGDClassifier._fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[39m# Clear iteration count for multiple call to fit.\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_ \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[0;32m--> 686\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[1;32m    687\u001b[0m     X,\n\u001b[1;32m    688\u001b[0m     y,\n\u001b[1;32m    689\u001b[0m     alpha,\n\u001b[1;32m    690\u001b[0m     C,\n\u001b[1;32m    691\u001b[0m     loss,\n\u001b[1;32m    692\u001b[0m     learning_rate,\n\u001b[1;32m    693\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    694\u001b[0m     classes,\n\u001b[1;32m    695\u001b[0m     sample_weight,\n\u001b[1;32m    696\u001b[0m     coef_init,\n\u001b[1;32m    697\u001b[0m     intercept_init,\n\u001b[1;32m    698\u001b[0m )\n\u001b[1;32m    700\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39m>\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf\n\u001b[1;32m    703\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter\n\u001b[1;32m    704\u001b[0m ):\n\u001b[1;32m    705\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    706\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMaximum number of iteration reached before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    707\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mconvergence. Consider increasing max_iter to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    708\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mimprove the fit.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    709\u001b[0m         ConvergenceWarning,\n\u001b[1;32m    710\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee499_ML/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:581\u001b[0m, in \u001b[0;36mBaseSGDClassifier._partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_partial_fit\u001b[39m(\n\u001b[1;32m    567\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    568\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m     intercept_init,\n\u001b[1;32m    579\u001b[0m ):\n\u001b[1;32m    580\u001b[0m     first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclasses_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 581\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    582\u001b[0m         X,\n\u001b[1;32m    583\u001b[0m         y,\n\u001b[1;32m    584\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    585\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    586\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    587\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    588\u001b[0m         reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[1;32m    589\u001b[0m     )\n\u001b[1;32m    591\u001b[0m     n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m    593\u001b[0m     _check_partial_fit_first_call(\u001b[39mself\u001b[39m, classes)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee499_ML/lib/python3.9/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee499_ML/lib/python3.9/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee499_ML/lib/python3.9/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[1;32m    900\u001b[0m             array,\n\u001b[1;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee499_ML/lib/python3.9/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nPerceptron does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "#model 1: Perceptron\n",
    "\n",
    "perc_clf = Perceptron(tol=1e-3, random_state=13)\n",
    "perc_clf.fit(X_train, Y_train)\n",
    "Perceptron()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_clf.score(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee499_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
